{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#uploading train.csv\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2ULDj229M81x",
        "outputId": "095b1a48-d3c4-41a3-ecfd-6b1d9704567f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e83fd63-7561-4c5d-8320-b10fe2c525b8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e83fd63-7561-4c5d-8320-b10fe2c525b8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading train.csv\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "SUlAmzUwM888",
        "outputId": "81f1ff7d-2eb8-45f6-a0e5-d58550eac283"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c02d1412-c12c-488c-b392-d5e0ffc40c28\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c02d1412-c12c-488c-b392-d5e0ffc40c28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train.csv\")  # Use the exact filename as uploaded\n",
        "test_data = pd.read_csv(\"test.csv\")    # Use the exact filename as uploaded\n"
      ],
      "metadata": {
        "id": "lMUB5jPLk-C3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the missing value threshold\n",
        "missing_threshold = 0.6\n",
        "\n",
        "# Step 1: Drop columns with excessive missing values in train_data\n",
        "cols_to_keep = train_data.columns[train_data.isnull().mean() <= missing_threshold]\n",
        "train_data = train_data[cols_to_keep]\n",
        "test_data = test_data[cols_to_keep.intersection(test_data.columns)]\n",
        "\n",
        "# Step 2: Impute missing numerical values with the median of train_data\n",
        "numerical_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "for col in numerical_cols:\n",
        "    median_value = train_data[col].median()  # Compute median from train_data\n",
        "    train_data.loc[:, col] = train_data[col].fillna(median_value)  # Impute train_data\n",
        "    if col in test_data.columns:\n",
        "        test_data.loc[:, col] = test_data[col].fillna(median_value)  # Impute test_data\n",
        "\n",
        "# Step 3: Impute missing categorical values with the mode of train_data\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    mode_value = train_data[col].mode()[0]  # Compute mode from train_data\n",
        "    train_data.loc[:, col] = train_data[col].fillna(mode_value)  # Impute train_data\n",
        "    if col in test_data.columns:\n",
        "        test_data.loc[:, col] = test_data[col].fillna(mode_value)  # Impute test_data\n",
        "\n",
        "# Output the results\n",
        "print(\"Train Data Shape After Handling Missing Values:\", train_data.shape)\n",
        "print(\"Test Data Shape After Handling Missing Values:\", test_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br6fpMBdlDc8",
        "outputId": "d8d5c3a1-e010-4c74-e193-38cc35d9c81e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Shape After Handling Missing Values: (12654, 24)\n",
            "Test Data Shape After Handling Missing Values: (5852, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numerical columns present in both train and test datasets\n",
        "common_numerical_cols = list(set(numerical_cols).intersection(set(test_data.columns)))\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "train_data[common_numerical_cols] = scaler.fit_transform(train_data[common_numerical_cols])\n",
        "test_data[common_numerical_cols] = scaler.transform(test_data[common_numerical_cols])\n"
      ],
      "metadata": {
        "id": "Nk9SwO-nlGZZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove outliers using IQR\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    # Remove rows where values are outside the IQR bounds\n",
        "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "# Remove outliers in train_data for numerical columns\n",
        "for col in numerical_cols:\n",
        "    train_data = remove_outliers_iqr(train_data, col)\n",
        "\n",
        "# Output the results\n",
        "print(\"Outliers in train_data have been removed.\")\n",
        "print(\"Train Data Shape After Outlier Removal:\", train_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faEeloUKlMRz",
        "outputId": "9ba86114-73ea-4a27-ab88-9d4c2055d3a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers in train_data have been removed.\n",
            "Train Data Shape After Outlier Removal: (7250, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 1. Create 'booked_package' column\n",
        "train_data['booked_package'] = train_data[['package_accomodation', 'food_package', 'transport_package_mx',\n",
        "                                           'sightseeing_package', 'guided_tour_package',\n",
        "                                           'tour_arrangement']].any(axis=1)\n",
        "test_data['booked_package'] = test_data[['package_accomodation', 'food_package', 'transport_package_mx',\n",
        "                                         'sightseeing_package', 'guided_tour_package',\n",
        "                                         'tour_arrangement']].any(axis=1)\n",
        "\n",
        "# 2. Extract average age from 'age_bracket'\n",
        "def extract_average_age(age_range):\n",
        "    if '-' in age_range:\n",
        "        start, end = age_range.split('-')\n",
        "        return (int(start) + int(end)) // 2\n",
        "    elif '<' in age_range:\n",
        "        return 1  # Replace '<1' with 1\n",
        "    else:\n",
        "        try:\n",
        "            return int(age_range)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "\n",
        "train_data['age_bracket'] = train_data['age_bracket'].apply(extract_average_age)\n",
        "test_data['age_bracket'] = test_data['age_bracket'].apply(extract_average_age)\n",
        "\n",
        "# 3. Create 'island_to_mainland_ratio' column\n",
        "train_data['island_to_mainland_ratio'] = train_data['island_nights'] / (train_data['mainland_nights'] + 1e-5)\n",
        "test_data['island_to_mainland_ratio'] = test_data['island_nights'] / (test_data['mainland_nights'] + 1e-5)\n",
        "\n",
        "# 4. Create 'female_to_male_ratio' column\n",
        "train_data['female_to_male_ratio'] = train_data['female_count'] / (train_data['male_count'] + 1e-5)\n",
        "test_data['female_to_male_ratio'] = test_data['female_count'] / (test_data['male_count'] + 1e-5)\n",
        "\n",
        "#5. Convert 'days_before_booked' to numeric\n",
        "def days_to_numeric(days):\n",
        "    if pd.isna(days):\n",
        "        return np.nan\n",
        "    elif '+' in days:\n",
        "        return int(days.replace('+', ''))\n",
        "    elif '-' in days:\n",
        "        start, end = days.split('-')\n",
        "        return (int(start) + int(end)) // 2\n",
        "    else:\n",
        "        return int(days)\n",
        "\n",
        "train_data['days_before_booked_numeric'] = train_data['days_before_booked'].apply(days_to_numeric)\n",
        "test_data['days_before_booked_numeric'] = test_data['days_before_booked'].apply(days_to_numeric)\n",
        "\n",
        "def categorize_tour_length(length):\n",
        "    if '7-14' in length:\n",
        "        return 'Short'\n",
        "    elif '30+' in length:\n",
        "        return 'Long'\n",
        "    else:\n",
        "        return 'Medium'\n",
        "\n",
        "train_data['tour_length_category'] = train_data['tour_length'].apply(categorize_tour_length)\n",
        "test_data['tour_length_category'] = test_data['tour_length'].apply(categorize_tour_length)\n",
        "\n",
        "#Verify the engineered features\n",
        "print(\"Feature Engineering Completed.\")\n",
        "print(\"Train Data with New Features:\", train_data.head())\n",
        "print(\"Test Data with New Features:\", test_data.head())\n",
        "\n",
        "# Columns used to create 'booked_package'\n",
        "package_columns = ['package_accomodation', 'food_package', 'transport_package_mx',\n",
        "                   'sightseeing_package', 'guided_tour_package', 'tour_arrangement']\n",
        "\n",
        "# Drop the redundant columns from both train_data and test_data\n",
        "train_data = train_data.drop(columns=package_columns, errors='ignore')\n",
        "test_data = test_data.drop(columns=package_columns, errors='ignore')\n",
        "\n",
        "# Verify the remaining columns\n",
        "print(\"Redundant package columns dropped.\")\n",
        "print(\"Train Data Columns After Dropping:\", train_data.columns)\n",
        "print(\"Test Data Columns After Dropping:\", test_data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Shu3CCnk0b",
        "outputId": "34065313-7f21-4517-ecfd-adaca340ffdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Engineering Completed.\n",
            "Train Data with New Features:            trip_ID visitor_nation  age_bracket travelling_with  female_count  \\\n",
            "3  tour_idkoh8mkgr          ITALY         34.0     With Spouse      0.044374   \n",
            "4  tour_idkmsfa00a          ITALY         34.0     With Spouse      0.044374   \n",
            "6  tour_iddge8fz8p          INDIA         34.0     With Spouse      0.044374   \n",
            "7  tour_ida5537syq          KENYA         54.0           Alone     -0.744259   \n",
            "8  tour_idhagcpzkz        AUSTRIA         21.0     With Spouse      0.044374   \n",
            "\n",
            "   male_count        key_activity             trip_purpose first_time_visitor  \\\n",
            "3   -0.007617     Widlife Tourism     Leisure and Holidays                Yes   \n",
            "4   -0.007617       Beach Tourism     Leisure and Holidays                Yes   \n",
            "6   -0.007617     Hunting Tourism                 Business                 No   \n",
            "7   -0.007617  Conference Tourism  Meetings and Conference                 No   \n",
            "8   -0.007617     Widlife Tourism     Leisure and Holidays                Yes   \n",
            "\n",
            "   mainland_nights  ...  insurance_package days_before_booked  \\\n",
            "3        -0.632740  ...                 No               8-14   \n",
            "4        -0.632740  ...                 No                90+   \n",
            "6        -0.289049  ...                 No                90+   \n",
            "7        -0.564002  ...                 No                90+   \n",
            "8         0.742023  ...                 No              61-90   \n",
            "\n",
            "  weather_at_arrival tour_length category booked_package  \\\n",
            "3             sunny,        7-14      0.0           True   \n",
            "4             sunny,        7-14      0.0           True   \n",
            "6             sunny,         30+      0.0           True   \n",
            "7            cloudy,        7-14      2.0           True   \n",
            "8              other        7-14      0.0           True   \n",
            "\n",
            "  island_to_mainland_ratio female_to_male_ratio days_before_booked_numeric  \\\n",
            "3                -1.380622            -5.833201                         11   \n",
            "4                -1.380622            -5.833201                         90   \n",
            "6                 0.348419            -5.833201                         90   \n",
            "7                 0.869540            97.837204                         90   \n",
            "8                 1.965034            -5.833201                         75   \n",
            "\n",
            "  tour_length_category  \n",
            "3                Short  \n",
            "4                Short  \n",
            "6                 Long  \n",
            "7                Short  \n",
            "8                Short  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "Test Data with New Features:            trip_ID visitor_nation  age_bracket               travelling_with  \\\n",
            "0  tour_id8gzpck76          CONGO         34.0                         Alone   \n",
            "1  tour_idow1zxkou     SWIZERLAND         54.0                   With Spouse   \n",
            "2  tour_idue7esfqz         MEXICO         54.0  With Other Friends/Relatives   \n",
            "3  tour_idnj3mjzpb          JAPAN         34.0  With Other Friends/Relatives   \n",
            "4  tour_ida3us5yk2          SPAIN         34.0  With Other Friends/Relatives   \n",
            "\n",
            "   female_count  male_count      key_activity          trip_purpose  \\\n",
            "0     -0.744259   -0.007617   Widlife Tourism              Business   \n",
            "1      0.044374   -0.007617   Widlife Tourism  Leisure and Holidays   \n",
            "2      0.833007   -0.817592  Cultural Tourism  Leisure and Holidays   \n",
            "3      0.044374   -0.007617   Widlife Tourism  Leisure and Holidays   \n",
            "4      0.833007   -0.817592  Wildlife Tourism  Leisure and Holidays   \n",
            "\n",
            "  first_time_visitor  mainland_nights  ...  guided_tour_package  \\\n",
            "0                 No         0.329594  ...                   No   \n",
            "1                Yes        -0.082835  ...                  Yes   \n",
            "2                Yes        -0.426525  ...                  Yes   \n",
            "3                Yes        -0.289049  ...                  Yes   \n",
            "4                Yes        -0.632740  ...                   No   \n",
            "\n",
            "  insurance_package days_before_booked weather_at_arrival tour_length  \\\n",
            "0                No             15-30              sunny,       15-30   \n",
            "1                No              61-90             Stormy         1-6   \n",
            "2                No               1-7              Stormy         30+   \n",
            "3                No                90+             sunny,        7-14   \n",
            "4               Yes              61-90             Stormy         30+   \n",
            "\n",
            "  booked_package island_to_mainland_ratio female_to_male_ratio  \\\n",
            "0           True                -1.487885            97.837204   \n",
            "1           True                -5.841913            -5.833201   \n",
            "2           True                -1.591284            -1.018866   \n",
            "3           True                 1.696703            -5.833201   \n",
            "4           True                -1.072665            -1.018866   \n",
            "\n",
            "  days_before_booked_numeric tour_length_category  \n",
            "0                         22               Medium  \n",
            "1                         75               Medium  \n",
            "2                          4                 Long  \n",
            "3                         90                Short  \n",
            "4                         75                 Long  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "Redundant package columns dropped.\n",
            "Train Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'female_count', 'male_count', 'key_activity', 'trip_purpose',\n",
            "       'first_time_visitor', 'mainland_nights', 'island_nights',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'days_before_booked', 'weather_at_arrival',\n",
            "       'tour_length', 'category', 'booked_package', 'island_to_mainland_ratio',\n",
            "       'female_to_male_ratio', 'days_before_booked_numeric',\n",
            "       'tour_length_category'],\n",
            "      dtype='object')\n",
            "Test Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'female_count', 'male_count', 'key_activity', 'trip_purpose',\n",
            "       'first_time_visitor', 'mainland_nights', 'island_nights',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'days_before_booked', 'weather_at_arrival',\n",
            "       'tour_length', 'booked_package', 'island_to_mainland_ratio',\n",
            "       'female_to_male_ratio', 'days_before_booked_numeric',\n",
            "       'tour_length_category'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the specified columns from both train_data and test_data\n",
        "columns_to_drop = ['female_count', 'male_count', 'island_nights', 'mainland_nights']\n",
        "\n",
        "train_data.drop(columns=columns_to_drop, inplace=True)\n",
        "test_data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Check the first few rows of train_data and test_data to confirm the columns are dropped\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9oPnI6v2aUl",
        "outputId": "2fae150c-b903-4a24-d74c-5b9ff114a53d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           trip_ID visitor_nation  age_bracket travelling_with  \\\n",
            "3  tour_idkoh8mkgr          ITALY         34.0     With Spouse   \n",
            "4  tour_idkmsfa00a          ITALY         34.0     With Spouse   \n",
            "6  tour_iddge8fz8p          INDIA         34.0     With Spouse   \n",
            "7  tour_ida5537syq          KENYA         54.0           Alone   \n",
            "8  tour_idhagcpzkz        AUSTRIA         21.0     With Spouse   \n",
            "\n",
            "         key_activity             trip_purpose first_time_visitor  \\\n",
            "3     Widlife Tourism     Leisure and Holidays                Yes   \n",
            "4       Beach Tourism     Leisure and Holidays                Yes   \n",
            "6     Hunting Tourism                 Business                 No   \n",
            "7  Conference Tourism  Meetings and Conference                 No   \n",
            "8     Widlife Tourism     Leisure and Holidays                Yes   \n",
            "\n",
            "  transport_package_international               source_of_info  \\\n",
            "3                              No  Travel agent, tour operator   \n",
            "4                             Yes  Travel agent, tour operator   \n",
            "6                              No  Travel agent, tour operator   \n",
            "7                              No                       Others   \n",
            "8                              No  Travel agent, tour operator   \n",
            "\n",
            "  insurance_package days_before_booked weather_at_arrival tour_length  \\\n",
            "3                No               8-14             sunny,        7-14   \n",
            "4                No                90+             sunny,        7-14   \n",
            "6                No                90+             sunny,         30+   \n",
            "7                No                90+            cloudy,        7-14   \n",
            "8                No              61-90              other        7-14   \n",
            "\n",
            "   category  booked_package  island_to_mainland_ratio  female_to_male_ratio  \\\n",
            "3       0.0            True                 -1.380622             -5.833201   \n",
            "4       0.0            True                 -1.380622             -5.833201   \n",
            "6       0.0            True                  0.348419             -5.833201   \n",
            "7       2.0            True                  0.869540             97.837204   \n",
            "8       0.0            True                  1.965034             -5.833201   \n",
            "\n",
            "   days_before_booked_numeric tour_length_category  \n",
            "3                          11                Short  \n",
            "4                          90                Short  \n",
            "6                          90                 Long  \n",
            "7                          90                Short  \n",
            "8                          75                Short  \n",
            "           trip_ID visitor_nation  age_bracket               travelling_with  \\\n",
            "0  tour_id8gzpck76          CONGO         34.0                         Alone   \n",
            "1  tour_idow1zxkou     SWIZERLAND         54.0                   With Spouse   \n",
            "2  tour_idue7esfqz         MEXICO         54.0  With Other Friends/Relatives   \n",
            "3  tour_idnj3mjzpb          JAPAN         34.0  With Other Friends/Relatives   \n",
            "4  tour_ida3us5yk2          SPAIN         34.0  With Other Friends/Relatives   \n",
            "\n",
            "       key_activity          trip_purpose first_time_visitor  \\\n",
            "0   Widlife Tourism              Business                 No   \n",
            "1   Widlife Tourism  Leisure and Holidays                Yes   \n",
            "2  Cultural Tourism  Leisure and Holidays                Yes   \n",
            "3   Widlife Tourism  Leisure and Holidays                Yes   \n",
            "4  Wildlife Tourism  Leisure and Holidays                Yes   \n",
            "\n",
            "  transport_package_international               source_of_info  \\\n",
            "0                              No           Friends, relatives   \n",
            "1                             Yes  Travel agent, tour operator   \n",
            "2                             Yes  Travel agent, tour operator   \n",
            "3                              No                       Others   \n",
            "4                              No  Travel agent, tour operator   \n",
            "\n",
            "  insurance_package days_before_booked weather_at_arrival tour_length  \\\n",
            "0                No             15-30              sunny,       15-30   \n",
            "1                No              61-90             Stormy         1-6   \n",
            "2                No               1-7              Stormy         30+   \n",
            "3                No                90+             sunny,        7-14   \n",
            "4               Yes              61-90             Stormy         30+   \n",
            "\n",
            "   booked_package  island_to_mainland_ratio  female_to_male_ratio  \\\n",
            "0            True                 -1.487885             97.837204   \n",
            "1            True                 -5.841913             -5.833201   \n",
            "2            True                 -1.591284             -1.018866   \n",
            "3            True                  1.696703             -5.833201   \n",
            "4            True                 -1.072665             -1.018866   \n",
            "\n",
            "   days_before_booked_numeric tour_length_category  \n",
            "0                          22               Medium  \n",
            "1                          75               Medium  \n",
            "2                           4                 Long  \n",
            "3                          90                Short  \n",
            "4                          75                 Long  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer to fill missing values with the median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Impute missing values in the 'age_bracket' column\n",
        "train_data['age_bracket'] = imputer.fit_transform(train_data[['age_bracket']])\n",
        "test_data['age_bracket'] = imputer.fit_transform(test_data[['age_bracket']])\n",
        "# Define the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale only the 'age_bracket' column in train_data and test_data\n",
        "train_data['age_bracket'] = scaler.fit_transform(train_data[['age_bracket']])\n",
        "test_data['age_bracket'] = scaler.fit_transform(test_data[['age_bracket']])\n",
        "\n",
        "# Check the first few rows of train_data and test_data to confirm scaling\n",
        "print(train_data[['age_bracket']].head())\n",
        "print(test_data[['age_bracket']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl9rLsff2d5d",
        "outputId": "fa6dc0b0-6e80-4810-b7a1-ea265256f912"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age_bracket\n",
            "3    -0.486059\n",
            "4    -0.486059\n",
            "6    -0.486059\n",
            "7     1.350659\n",
            "8    -1.679926\n",
            "   age_bracket\n",
            "0    -0.360737\n",
            "1     1.392105\n",
            "2     1.392105\n",
            "3    -0.360737\n",
            "4    -0.360737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'days_before_booked' column from train_data and test_data\n",
        "train_data = train_data.drop(columns=['days_before_booked'], errors='ignore')\n",
        "test_data = test_data.drop(columns=['days_before_booked'], errors='ignore')\n",
        "\n",
        "# Verify the remaining columns\n",
        "print(\"Column 'days_before_booked' removed.\")\n",
        "print(\"Train Data Columns After Dropping:\", train_data.columns)\n",
        "print(\"Test Data Columns After Dropping:\", test_data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjSyJ1I92ibV",
        "outputId": "fc9a675f-6ccc-4c24-8091-f81c739668d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'days_before_booked' removed.\n",
            "Train Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'key_activity', 'trip_purpose', 'first_time_visitor',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'weather_at_arrival', 'tour_length', 'category',\n",
            "       'booked_package', 'island_to_mainland_ratio', 'female_to_male_ratio',\n",
            "       'days_before_booked_numeric', 'tour_length_category'],\n",
            "      dtype='object')\n",
            "Test Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'key_activity', 'trip_purpose', 'first_time_visitor',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'weather_at_arrival', 'tour_length',\n",
            "       'booked_package', 'island_to_mainland_ratio', 'female_to_male_ratio',\n",
            "       'days_before_booked_numeric', 'tour_length_category'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'tour_length' column from train_data and test_data\n",
        "train_data = train_data.drop(columns=['tour_length'], errors='ignore')\n",
        "test_data = test_data.drop(columns=['tour_length'], errors='ignore')\n",
        "\n",
        "# Verify the remaining columns\n",
        "print(\"Column 'tour_length' removed.\")\n",
        "print(\"Train Data Columns After Dropping:\", train_data.columns)\n",
        "print(\"Test Data Columns After Dropping:\", test_data.columns)\n",
        "#Calculate the proportion of category 0, 1, and 2 for each visitor_nation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYE0uIhf2pYh",
        "outputId": "0876559e-9843-4cb0-a29e-9878dfad37e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'tour_length' removed.\n",
            "Train Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'key_activity', 'trip_purpose', 'first_time_visitor',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'weather_at_arrival', 'category', 'booked_package',\n",
            "       'island_to_mainland_ratio', 'female_to_male_ratio',\n",
            "       'days_before_booked_numeric', 'tour_length_category'],\n",
            "      dtype='object')\n",
            "Test Data Columns After Dropping: Index(['trip_ID', 'visitor_nation', 'age_bracket', 'travelling_with',\n",
            "       'key_activity', 'trip_purpose', 'first_time_visitor',\n",
            "       'transport_package_international', 'source_of_info',\n",
            "       'insurance_package', 'weather_at_arrival', 'booked_package',\n",
            "       'island_to_mainland_ratio', 'female_to_male_ratio',\n",
            "       'days_before_booked_numeric', 'tour_length_category'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportion of category 0, 1, and 2 for each visitor_nation in train_data\n",
        "category_proportion = train_data.groupby('visitor_nation')['category'].value_counts(normalize=True).unstack(fill_value=0)\n",
        "\n",
        "# Function to assign spending category based on proportions\n",
        "def spending_category(nation):\n",
        "    # If the nation is not present in category_proportion, return 'unknown' or a default value\n",
        "    if nation not in category_proportion.index:\n",
        "        return 'unknown'\n",
        "\n",
        "    # Otherwise, calculate the proportions\n",
        "    high_spender_prop = category_proportion.loc[nation, 0]  # Proportion for high spender (category 0)\n",
        "    moderate_spender_prop = category_proportion.loc[nation, 1]  # Proportion for moderate spender (category 1)\n",
        "    low_spender_prop = category_proportion.loc[nation, 2]  # Proportion for low spender (category 2)\n",
        "\n",
        "    # Determine the category with the highest proportion for the nationality\n",
        "    if high_spender_prop > moderate_spender_prop and high_spender_prop > low_spender_prop:\n",
        "        return 'high_spender'\n",
        "    elif low_spender_prop > high_spender_prop and low_spender_prop > moderate_spender_prop:\n",
        "        return 'low_spender'\n",
        "    else:\n",
        "        return 'moderate_spender'\n",
        "\n",
        "# Apply the function to assign 'visitor_spending_category' to train_data\n",
        "train_data['visitor_spending_category'] = train_data['visitor_nation'].map(spending_category)\n",
        "\n",
        "# Similarly, apply the function to assign 'visitor_spending_category' to test_data\n",
        "test_data['visitor_spending_category'] = test_data['visitor_nation'].map(spending_category)\n",
        "\n",
        "# Check the new feature in both datasets\n",
        "print(\"Train Data with New Feature:\")\n",
        "print(train_data[['visitor_nation', 'category', 'visitor_spending_category']].head())\n",
        "\n",
        "print(\"Test Data with New Feature:\")\n",
        "print(test_data[['visitor_nation', 'visitor_spending_category']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te_sy6if2vNY",
        "outputId": "29302f0e-74aa-4c6e-ad70-7ec0d9367a45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data with New Feature:\n",
            "  visitor_nation  category visitor_spending_category\n",
            "3          ITALY       0.0              high_spender\n",
            "4          ITALY       0.0              high_spender\n",
            "6          INDIA       0.0          moderate_spender\n",
            "7          KENYA       2.0          moderate_spender\n",
            "8        AUSTRIA       0.0              high_spender\n",
            "Test Data with New Feature:\n",
            "  visitor_nation visitor_spending_category\n",
            "0          CONGO          moderate_spender\n",
            "1     SWIZERLAND              high_spender\n",
            "2         MEXICO          moderate_spender\n",
            "3          JAPAN          moderate_spender\n",
            "4          SPAIN              high_spender\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding\n",
        "\n",
        "# Concatenate train_data and test_data for consistent encoding\n",
        "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = combined_data.select_dtypes(include=['object']).columns\n",
        "categorical_cols = [col for col in categorical_cols if col != 'trip_ID']\n",
        "# Initialize a dictionary to store mappings for each categorical column\n",
        "label_mappings = {}\n",
        "\n",
        "# Label encode each categorical column\n",
        "for col in categorical_cols:\n",
        "    # Get unique values and assign incremental labels\n",
        "    unique_values = combined_data[col].dropna().unique()\n",
        "    col_mapping = {val: idx + 1 for idx, val in enumerate(sorted(unique_values))}  # Map to 1, 2, 3...\n",
        "\n",
        "    # Apply mapping to the column\n",
        "    combined_data[col] = combined_data[col].map(col_mapping)\n",
        "\n",
        "    # Store the mapping for later use\n",
        "    label_mappings[col] = col_mapping\n",
        "\n",
        "# Split back into train_data and test_data\n",
        "train_data = combined_data.iloc[:len(train_data)].reset_index(drop=True)\n",
        "test_data = combined_data.iloc[len(train_data):].reset_index(drop=True)\n",
        "\n",
        "# Verify the results\n",
        "print(\"Categorical columns label-encoded.\")\n",
        "print(\"Train Data Shape:\", train_data.shape)\n",
        "print(\"Test Data Shape:\", test_data.shape)\n",
        "print(\"Label Mappings:\", label_mappings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIOXViVJlY-1",
        "outputId": "fc15153b-68e5-4ba9-b488-0164465c4e81"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns label-encoded.\n",
            "Train Data Shape: (7250, 18)\n",
            "Test Data Shape: (5852, 18)\n",
            "Label Mappings: {'visitor_nation': {'AFGHANISTAN': 1, 'ALGERIA': 2, 'ANGOLA': 3, 'ARGENTINA': 4, 'ARMENIA': 5, 'AUSTRALIA': 6, 'AUSTRIA': 7, 'BAHRAIN': 8, 'BANGLADESH': 9, 'BARBADOS': 10, 'BELGIUM': 11, 'BERMUDA': 12, 'BOSNIA': 13, 'BOTSWANA': 14, 'BRAZIL': 15, 'BULGARIA': 16, 'BURGARIA': 17, 'BURUNDI': 18, 'CAMBODIA': 19, 'CAMEROON': 20, 'CANADA': 21, 'CAPE VERDE': 22, 'CHILE': 23, 'CHINA': 24, 'COLOMBIA': 25, 'COMORO': 26, 'CONGO': 27, 'COSTARICA': 28, 'CROATIA': 29, 'CYPRUS': 30, 'CZECH REPUBLIC': 31, 'DENMARK': 32, 'DJIBOUT': 33, 'DOMINICA': 34, 'DRC': 35, 'ECUADO': 36, 'EGYPT': 37, 'ERITREA': 38, 'ESTONIA': 39, 'ETHIOPIA': 40, 'FINLAND': 41, 'FRANCE': 42, 'GAMBIA': 43, 'GEORGIA': 44, 'GERMANY': 45, 'GHANA': 46, 'GREECE': 47, 'HUNGARY': 48, 'ICELAND': 49, 'INDIA': 50, 'INDONESIA': 51, 'IRAN': 52, 'IRELAND': 53, 'ISRAEL': 54, 'ITALY': 55, 'JAMAICA': 56, 'JAPAN': 57, 'JORDAN': 58, 'KENYA': 59, 'KOREA': 60, 'KUWAIT': 61, 'LATVIA': 62, 'LEBANON': 63, 'LESOTHO': 64, 'LITHUANIA': 65, 'LUXEMBOURG': 66, 'MACEDONIA': 67, 'MADAGASCAR': 68, 'MALAWI': 69, 'MALAYSIA': 70, 'MALT': 71, 'MAURITIUS': 72, 'MEXICO': 73, 'MONECASQUE': 74, 'MONTENEGRO': 75, 'MORROCO': 76, 'MOZAMBIQUE': 77, 'NAMIBIA': 78, 'NEPAL': 79, 'NETHERLANDS': 80, 'NEW ZEALAND': 81, 'NIGERIA': 82, 'NORWAY': 83, 'OMAN': 84, 'PAKISTAN': 85, 'PAPUA NEW GUINEA': 86, 'PERU': 87, 'PHILIPINES': 88, 'POLAND': 89, 'PORTUGAL': 90, 'QATAR': 91, 'ROMANIA': 92, 'RUSSIA': 93, 'RWANDA': 94, 'SAUD ARABIA': 95, 'SCOTLAND': 96, 'SENEGAL': 97, 'SERBIA': 98, 'SEYCHELLES': 99, 'SINGAPORE': 100, 'SLOVAKIA': 101, 'SLOVENIA': 102, 'SOMALI': 103, 'SOUTH AFRICA': 104, 'SPAIN': 105, 'SRI LANKA': 106, 'SUDAN': 107, 'SWAZILAND': 108, 'SWEDEN': 109, 'SWIZERLAND': 110, 'TAIWAN': 111, 'TANZANIA': 112, 'THAILAND': 113, 'TRINIDAD TOBACCO': 114, 'TUNISIA': 115, 'TURKEY': 116, 'UAE': 117, 'UGANDA': 118, 'UKRAIN': 119, 'UNITED ARAB EMIRATES': 120, 'UNITED KINGDOM': 121, 'UNITED STATES OF AMERICA': 122, 'URUGUAY': 123, 'VENEZUELA': 124, 'VIETNAM': 125, 'YEMEN': 126, 'ZAMBIA': 127, 'ZIMBABWE': 128}, 'travelling_with': {'Alone': 1, 'With Children': 2, 'With Other Friends/Relatives': 3, 'With Spouse': 4, 'With Spouse and Children': 5}, 'key_activity': {'Beach Tourism': 1, 'Bird Tourism': 2, 'Business': 3, 'Conference Tourism': 4, 'Cultural Tourism': 5, 'Diving and Sport Fishing': 6, 'Hunting Tourism': 7, 'Mountain Climbing': 8, 'Widlife Tourism': 9, 'Wildlife Tourism': 10}, 'trip_purpose': {'Business': 1, 'Leisure and Holidays': 2, 'Medical': 3, 'Meetings and Conference': 4, 'Other': 5, 'Scientific and Academic': 6, 'Visiting Friends and Relatives': 7, 'Volunteering': 8}, 'first_time_visitor': {'No': 1, 'Yes': 2}, 'transport_package_international': {'No': 1, 'Yes': 2}, 'source_of_info': {'Friends, relatives': 1, 'Inflight magazines': 2, 'Mexican Mission Abroad': 3, 'Newspaper, magazines, brochures': 4, 'Others': 5, 'Radio, TV, Web': 6, 'Trade fair': 7, 'Travel agent, tour operator': 8}, 'insurance_package': {'No': 1, 'Yes': 2}, 'weather_at_arrival': {'Rainy': 1, 'Stormy': 2, 'Windy,': 3, 'cloudy,': 4, 'humid': 5, 'other': 6, 'sunny,': 7}, 'tour_length_category': {'Long': 1, 'Medium': 2, 'Short': 3}, 'visitor_spending_category': {'high_spender': 1, 'low_spender': 2, 'moderate_spender': 3, 'unknown': 4}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train_data into features and target\n",
        "X = train_data.drop(columns=['category', 'trip_ID'])\n",
        "y = train_data['category']\n",
        "\n",
        "# Split into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "R7xf6iS4lckC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no missing values in X_train and X_val\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop, Adagrad, Adamax\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log = log_reg.predict(X_val)\n",
        "log_reg_acc = accuracy_score(y_val, y_pred_log)\n",
        "print(\"Logistic Regression Accuracy:\", log_reg_acc)\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_val)\n",
        "svm_acc = accuracy_score(y_val, y_pred_svm)\n",
        "print(\"SVM Accuracy:\", svm_acc)\n",
        "\n",
        "# Neural Network Variations\n",
        "def create_nn(input_dim, optimizer, dropout_rate=0.2, reg=0.01, hidden_layer_size=256):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_layer_size, input_dim=input_dim, activation='relu', kernel_regularizer=l2(reg)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(hidden_layer_size // 2, activation='relu', kernel_regularizer=l2(reg)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(3, activation='softmax'))  # Assuming 3 output classes\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# One-hot encode the labels for NN\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# Optimizers to try\n",
        "optimizers = [\n",
        "        SGD(learning_rate=0.01, momentum=0.9),\n",
        "    Adam(learning_rate=0.001),\n",
        "    Adadelta(learning_rate=1.0),\n",
        "    RMSprop(learning_rate=0.001),\n",
        "    Adagrad(learning_rate=0.01),\n",
        "    Adamax(learning_rate=0.002)\n",
        "]\n",
        "\n",
        "nn_accuracies = {}\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    model = create_nn(input_dim, optimizer, dropout_rate=0.3, reg=0.01, hidden_layer_size=256)\n",
        "    model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0, validation_data=(X_val, y_val_nn))\n",
        "    loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "    nn_accuracies[str(optimizer)] = acc\n",
        "    print(f\"NN with {optimizer.__class__.__name__} Accuracy: {acc}\")\n",
        "\n",
        "# Select the best model\n",
        "best_model = None\n",
        "best_model_type = \"\"\n",
        "if log_reg_acc >= svm_acc and log_reg_acc >= max(nn_accuracies.values()):\n",
        "    best_model = log_reg\n",
        "    best_model_type = \"Logistic Regression\"\n",
        "elif svm_acc >= log_reg_acc and svm_acc >= max(nn_accuracies.values()):\n",
        "    best_model = svm\n",
        "    best_model_type = \"SVM\"\n",
        "else:\n",
        "    best_optimizer = max(nn_accuracies, key=nn_accuracies.get)\n",
        "    best_model = create_nn(input_dim, eval(best_optimizer))\n",
        "    best_model_type = f\"Neural Network with {best_optimizer}\"\n",
        "\n",
        "print(f\"Best Model: {best_model_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD5ZdgMnM0NK",
        "outputId": "f52d2d4f-e896-40d5-c64b-c74aa1cd8d84"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.716551724137931\n",
            "SVM Accuracy: 0.6496551724137931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with SGD Accuracy: 0.6496551632881165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with Adam Accuracy: 0.6951724290847778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with Adadelta Accuracy: 0.6979310512542725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with RMSprop Accuracy: 0.7027586102485657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with Adagrad Accuracy: 0.6593103408813477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN with Adamax Accuracy: 0.6937931180000305\n",
            "Best Model: Logistic Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# def create_nn(input_dim, dropout_rate=0.3, reg=0.01):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(64, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(32, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(16, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(3, activation='softmax'))  # Assuming 3 output classes\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "unYH3Xqmiy2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop the 'trip_ID' column from X_test as it's not used for prediction\n",
        "X_test = test_data.drop(columns=['trip_ID'])\n",
        "\n",
        "# Ensure X_test has the same columns as the training data X_train\n",
        "# Assuming 'X_train' is the training data used to fit the model, get its columns:\n",
        "X_train_columns = X_train.columns\n",
        "\n",
        "# Align X_test columns with X_train (adding missing columns with default values, like 0)\n",
        "X_test = X_test.reindex(columns=X_train_columns, fill_value=0)\n",
        "\n",
        "# Make predictions on the test data using the aligned features\n",
        "test_data['category'] = best_model.predict(X_test)\n",
        "\n",
        "# Create the submission dataframe with 'trip_ID' and 'category'\n",
        "submission = test_data[['trip_ID', 'category']]\n",
        "\n",
        "# Save the submission to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Print success message\n",
        "print(\"Submission file created: submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZubYzq3tlofM",
        "outputId": "ff3275e1-a486-4cdb-8fdd-2ba8bb3761c6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file\n",
        "files.download('submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hveuqdtAlsqG",
        "outputId": "11bb178d-b070-4c9e-d4c1-c5db38cb0995"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ea836bbf-a67b-4a69-8041-2d5b0a2073d9\", \"submission.csv\", 117057)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different Models tried :"
      ],
      "metadata": {
        "id": "9U7LZP0379R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Required Libraries\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import f1_score\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "\n",
        "# # Training data preparation (assuming X_train, X_val, y_train, y_val are pre-split)\n",
        "# # Test data preparation (assuming test_df is preprocessed and available)\n",
        "\n",
        "# # Define individual models\n",
        "# rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "# xgb_model = XGBClassifier(random_state=42, n_estimators=100)\n",
        "# lr_model = LogisticRegression(random_state=42, max_iter=200)\n",
        "# gb_model = GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
        "# nn_model = MLPClassifier(random_state=42, max_iter=300)  # Neural Network\n",
        "\n",
        "# # Ensemble Voting Classifier\n",
        "# voting_clf = VotingClassifier(estimators=[\n",
        "#     ('rf', rf_model),\n",
        "#     ('xgb', xgb_model),\n",
        "#     ('lr', lr_model),\n",
        "#     ('gb', gb_model),\n",
        "#     ('nn', nn_model)\n",
        "# ], voting='soft')\n",
        "\n",
        "# # Training the Voting Classifier\n",
        "# voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate on validation data\n",
        "# y_pred = voting_clf.predict(X_val)\n",
        "# f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "# print(f\"F1 Score on Validation Set: {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGco1tP_9-6J",
        "outputId": "f434e903-f545-4cd5-8fb6-4aee1b8f06fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score on Validation Set: 0.7367426678294142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Drop the 'trip_ID' column from X_test as it's not used for prediction\n",
        "# X_test = test_data.drop(columns=['trip_ID'])\n",
        "\n",
        "# # Ensure X_test has the same columns as the training data X_train\n",
        "# # Assuming 'X_train' is the training data used to fit the model, get its columns:\n",
        "# X_train_columns = X_train.columns\n",
        "\n",
        "# # Align X_test columns with X_train (adding missing columns with default values, like 0)\n",
        "# X_test = X_test.reindex(columns=X_train_columns, fill_value=0)\n",
        "\n",
        "# # Make predictions on the test data using the aligned features\n",
        "# test_data['category'] = voting_clf.predict(X_test)\n",
        "\n",
        "# # Create the submission dataframe with 'trip_ID' and 'category'\n",
        "# submission = test_data[['trip_ID', 'category']]\n",
        "\n",
        "# # Save the submission to a CSV file\n",
        "# submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# # Print success message\n",
        "# print(\"Submission file created: submission.csv\")\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# # Download the file\n",
        "# files.download('submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vr2MvBEC_fu3",
        "outputId": "475d62f4-ee05-4a4c-fb08-6a034753e04f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_151a7484-4159-48b4-96a8-6c25e8d39fcb\", \"submission.csv\", 117057)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.neural_network import MLPClassifier  # For NN\n",
        "\n",
        "# base_learners = [\n",
        "#     ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),\n",
        "#     ('xgb', XGBClassifier(random_state=42, n_estimators=100)),\n",
        "#     ('gb', GradientBoostingClassifier(random_state=42, n_estimators=100)),\n",
        "#     ('ab', AdaBoostClassifier(algorithm='SAMME', random_state=42, n_estimators=100)),\n",
        "#     ('lgbm', LGBMClassifier(random_state=42, n_estimators=100)),\n",
        "#     ('lr', LogisticRegression(random_state=42, max_iter=1000)),  # Logistic Regression\n",
        "#     ('nn', MLPClassifier(random_state=42, max_iter=300))         # Neural Network\n",
        "# ]\n",
        "\n",
        "# meta_model =  LogisticRegression(random_state=42)\n",
        "# # meta_model =  MLPClassifier(random_state=42)\n",
        "# # meta_model =  LGBMClassifier(random_state=42)\n",
        "# # meta_model =  GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_model)\n",
        "\n",
        "\n",
        "# stacking_clf.fit(X_train, y_train)\n",
        "# y_pred = stacking_clf.predict(X_val)\n",
        "# f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "# print(f\"F1 Score on Validation Set: {f1}\")\n",
        "\n",
        "# test_predictions = stacking_clf.predict(X_test)\n",
        "# submission_df = pd.DataFrame({\n",
        "#     'trip_ID': test_df['trip_ID'],\n",
        "#     'category': test_predictions\n",
        "# })\n",
        "\n",
        "# # Save to CSV\n",
        "# submission_df.to_csv('submission_stacking_classifier_with_nn_lr.csv', index=False)\n",
        "\n",
        "# print(\"Submission file 'submission_stacking_classifier_with_nn_lr.csv' created successfully.\")"
      ],
      "metadata": {
        "id": "g-Fwk2gI-E0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# log_reg = LogisticRegression(max_iter=1000)\n",
        "# log_reg.fit(X_train, y_train)\n",
        "# y_pred_log = log_reg.predict(X_val)\n",
        "# log_reg_acc = accuracy_score(y_val, y_pred_log)\n",
        "# print(\"Logistic Regression Accuracy:\", log_reg_acc)\n"
      ],
      "metadata": {
        "id": "zKpQHlcSlAit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm = SVC()\n",
        "# svm.fit(X_train, y_train)\n",
        "# y_pred_svm = svm.predict(X_val)\n",
        "# svm_acc = accuracy_score(y_val, y_pred_svm)\n",
        "# print(\"SVM Accuracy:\", svm_acc)\n"
      ],
      "metadata": {
        "id": "UUKgGBVOlAuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# def create_nn(input_dim, dropout_rate=0.3, reg=0.01):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(64, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(32, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(16, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(3, activation='softmax'))\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "ow0A4XBtlA3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with Adam optimizer\n",
        "# adam_optimizer = Adam(learning_rate=0.001)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Training the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with Adam Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "EL8T-SzhlA6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with SGD optimizer\n",
        "# sgd_optimizer = SGD(learning_rate=0.01)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with SGD Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "rEXuVsbklBCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import Adadelta\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with Adadelta optimizer\n",
        "# adadelta_optimizer = Adadelta(learning_rate=1.0)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=adadelta_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Training the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with Adadelta Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "yXIvVcYK3GhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import RMSprop\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with RMSprop optimizer\n",
        "# rmsprop_optimizer = RMSprop(learning_rate=0.001)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=rmsprop_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Training the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with RMSprop Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "cSu0WJbu3L7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import Adamax\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with Adamax optimizer\n",
        "# adamax_optimizer = Adamax(learning_rate=0.002)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=adamax_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Training the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with Adamax Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "IBa5QAAK3O4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.optimizers import Adagrad\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_train_nn = to_categorical(y_train)\n",
        "# y_val_nn = to_categorical(y_val)\n",
        "\n",
        "# # Simple Neural Network without hidden layers\n",
        "# model = Sequential()\n",
        "# model.add(Dense(y_train_nn.shape[1], input_dim=X_train.shape[1], activation='softmax'))  # Output layer\n",
        "\n",
        "# # Compiling the model with Adagrad optimizer\n",
        "# adagrad_optimizer = Adagrad(learning_rate=0.01)  # You can adjust the learning rate here\n",
        "# model.compile(optimizer=adagrad_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Training the model\n",
        "# model.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(X_val, y_val_nn, verbose=0)\n",
        "# print(\"Neural Network with AdaGrad Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "qnLn5Mf73R9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# def create_nn(input_dim, dropout_rate=0.3, reg=0.01):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(64, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(32, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(16, activation='relu', kernel_regularizer=l2(reg)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(3, activation='softmax'))  # Assuming 3 output classes\n",
        "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "MVt-Y6Wm3gQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}